<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
<title>自然资源部一线码农——肖飞的博客：带你走进政务系统云原生的世界</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">






<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="/css/style.css">
<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>

</head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item " href="/archives">文章列表</a>
            
            <a class="navbar-item " href="/categories/Lifestyle">Lifestyle</a>
            
            <a class="navbar-item " href="/categories/Music">Music</a>
            
            <a class="navbar-item " href="/categories/Technology">Technology</a>
            
            <a class="navbar-item " href="/categories/Research">Research</a>
            
            <a class="navbar-item " href="/about">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" href="https://github.com/xyfigo">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/08/22/Presto（一）用例指南/" itemprop="url">Presto（一）用例指南</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-08-22T15:07:01.000Z" itemprop="datePublished">1 年前</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Technology/">Technology</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            7 分钟 读完 (约 999 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <h1 id="Presto不是什么"><a href="#Presto不是什么" class="headerlink" title="Presto不是什么"></a>Presto不是什么</h1><p>因为网上很多人错误地认为Presto是一个数据库，所以首先从反面定义Presto不是什么更有意义。</p>
<p>不要以为Presto能够解析并执行SQL就将其与标准的数据库混为一谈。Presto并不是一个普遍意义上的关系数据库。它无法替代诸如Mysql、PostgreSQL和Oracle这样的关系型数据库。Presto的设计目标不是为了处理OLTP工作，这与很多其他为优化数据仓库和分析型数据库而设计的数据库一样。</p>
<h1 id="Presto是什么"><a href="#Presto是什么" class="headerlink" title="Presto是什么"></a>Presto是什么</h1><p>Presto是一个面向大规模数据集通过分布式查询任务进行高效查询的工具。需要处理TB或PB级数据时，会经常使用与Hadoop和HDFS交互的工具。Presto的设计目标是为替换诸如Hive、Pig等使用MapReduce管道查询HDFS的工具提供另一种选择。Presto通过扩展还能够处理其他类型的数据源，包括传统关系型数据看看和其他No-SQL数据库例如Cassandra。</p>
<p>Presto设计用于处理数据仓库和数据分析业务：例如数据分析、聚合大规模数据和制作报表。这类应用场景经常被划分为OLAP范围。</p>
<h1 id="Presto核心概念"><a href="#Presto核心概念" class="headerlink" title="Presto核心概念"></a>Presto核心概念</h1><h2 id="连接器Connector"><a href="#连接器Connector" class="headerlink" title="连接器Connector"></a>连接器Connector</h2><p>连接器将Presto适配到一个数据源，例如Hive或关系型数据库。可以将连接器视为一个连接数据库的驱动。它实现了Presto的SPI，Presto依靠SPI标准接口与数据源进行互动。</p>
<p>Presto包括几个内置的连接器：JMX连接器，作为一个系统连接器提供对内置系统表的访问。Hive连接器。以及一个TPCH连接器用于服务TPC-H基准测试数据。第三方开发人员贡献了很多其他连接器，所以Presto能够适配许多不同类型的数据源。</p>
<p>每一个catalog都对应一个连接器。如果你查看catalog配置文件，会看到每个catalog都会有一个必需的配置项connector.name，它被catalog manager用于创建与catalog想匹配的连接器。可以为多个catalog指定相同的连接器，用于访问同类数据库的不同实例。例如你有两个Hive集群，你可以在一个Presto集群中配置两个catalog都使用Hive连接器，是你能够从两个Hive集群中查询数据。</p>
<h2 id="Catalog"><a href="#Catalog" class="headerlink" title="Catalog"></a>Catalog</h2><p>Presto的catalog包含schema模式和指向数据源的连接器的引用。例如，你可以配置一个JMX catalog，通过JMX连接器提供对JMX信息的访问。Presto可以在一个或多个catalog上运行SQL。其他catalog类型包括连接到Hive数据源的Hive catalog。</p>
<p>当使用Presto在解析表时，使用表的完全限定（fully-qualified）名，完全限定名以catalog为根。例如hive.test_data.test的完全限定名，表示hive库中的test_data模式中的test表。</p>
<p>catalog通过Presto配置文件目录下的属性文件进行定义。</p>
<h2 id="Schema"><a href="#Schema" class="headerlink" title="Schema"></a>Schema</h2><p>schema是一种组织表的方式。一个catalog和模式定义了一组可以被查询的表。当使用Presto访问Hive或关系型数据库例如MySQL时，schema跟目标数据库中的具有相同的概念。其他类型的连接器可能会选择以一种对底层数据源有意义的方式将表组织为模式。</p>
<h2 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h2><p>一个表是一组无序的行，这些行由不同类型的列组成。这与关系型数据库概念相同。源数据到表的映射关系由连接器进行定义。</p>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/08/19/把数据基础做实做准/" itemprop="url">把数据基础做实做准</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-08-19T00:44:00.000Z" itemprop="datePublished">1 年前</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Technology/">Technology</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            4 分钟 读完 (约 639 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>为把数据基础做实做准，需统筹考虑决策支持系统中数据从来源、分析处理到产生决策价值并提供决策使用等全生命周期的过程治理。数据基础是整个治理过程中最基本的工作，关系到后续各个过程。打牢数据基础，主要有三个方面的工作。</p>
<p>一是建立清晰的数据目录。对于决策支持系统中的每类数据建立一个数据条目，包括名称、来源、数量、业务类别、更新频率、数据类型、访问权限等信息，从数据的业务、存储、使用和持续运营的多个角度进行梳理。数据目录作为决策支持系统最基础的战略性资产，用于数据登记、管理、更新和提供服务。</p>
<p>二是做好不同类型数据的管理。用于信息研究和决策支持的数据从结构上分为三类，第一类是以舆情、情报、文献等知识数据组成的非结构化数据，第二类是以统计数据组成的非关系模式的半结构化数据，第三类是以业务系统产生的管理数据组成的结构化数据，它通常存储于关系型数据库中。上述分类可见他们在存储结构、更新方式、分析方法和使用方式上有较大的差异，需要因地制宜对每类数据使用与其相适应的管理方法和技术。</p>
<p>三是做好数据的持续运营。打牢数据基础不是一蹴而就、一气呵成的, 需要一个持续的过程。积累的数据越多，周期越长,数据价值才越大，利用数据所做的研究也越多。数据的更新和积累属于决策支持系统运行维护的日常性工作，需要坚持不懈地去做。对于每一项数据资源需要从运营的角度建立常态化更新机制，尽量运用信息化手段实现自动更新并监控更新过程。对于无法自动化处理的更新过程，需要明确更新任务和工作量，作为日常数据处理任务进行统筹安排。</p>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/08/14/基于MongoDB-Spark的大数据分析解决方案/" itemprop="url">基于MongoDB+Spark的大数据分析解决方案</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-08-14T14:06:13.000Z" itemprop="datePublished">1 年前</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Technology/">Technology</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            37 分钟 读完 (约 5484 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>本文转自：<a href="https://www.cnblogs.com/hanson1/p/7105288.html" target="_blank" rel="noopener">https://www.cnblogs.com/hanson1/p/7105288.html</a></p>
<h3 id="Spark介绍"><a href="#Spark介绍" class="headerlink" title="Spark介绍"></a>Spark介绍</h3><p>按照官方的定义，<a href="http://lib.csdn.net/base/spark" target="_blank" rel="noopener">Spark</a> 是一个通用，快速，适用于大规模数据的处理引擎。</p>
<ul>
<li>通用性：我们可以使用Spark SQL来执行常规分析， Spark Streaming 来流数据处理， 以及用Mlib来执行机器学习等。Java，python，scala及R语言的支持也是其通用性的表现之一。</li>
<li>快速： 这个可能是Spark成功的最初原因之一，主要归功于其基于内存的运算方式。当需要处理的数据需要反复迭代时，Spark可以直接在内存中暂存数据，而无需像Map Reduce一样需要把数据写回磁盘。官方的数据表明：它可以比传统的Map Reduce快上100倍。</li>
<li>大规模：原生支持HDFS，并且其计算节点支持弹性扩展，利用大量廉价计算资源并发的特点来支持大规模数据处理。</li>
</ul>
<h3 id="我们能用它做什么"><a href="#我们能用它做什么" class="headerlink" title="我们能用它做什么"></a>我们能用它做什么</h3><p>那我们能用Spark来做什么呢？ 场景数不胜数。</p>
<p>最简单的可以只是统计一下某一个页面多少点击量，复杂的可以通过<a href="http://lib.csdn.net/base/machinelearning" target="_blank" rel="noopener">机器学习</a>来预测。</p>
<p><em>个性化</em> 是一个常见的案例，比如说，Yahoo的网站首页使用Spark来实现快速的用户兴趣分析。应该在首页显示什么新闻？原始的做法是让用户选择分类；聪明的做法就是在用户交互的过程中揣摩用户可能喜欢的文章。另一方面就是要在新闻进来时候进行分析并确定什么样的用户是可能的受众。新闻的时效性非常高，按照常规的MapReduce做法，对于Yahoo几亿用户及海量的文章，可能需要计算一天才能得出结果。Spark的高效运算可以在这里得到充分的运用，来保证新闻推荐在数十分钟或更短时间内完成。另外，如美国最大的有线电视商Comcast用它来做节目推荐，最近刚和滴滴联姻的uber用它实时订单分析，优酷则在Spark上实现了商业<a href="http://lib.csdn.net/base/aiplanning" target="_blank" rel="noopener">智能</a>的升级版。</p>
<h3 id="Spark生态系统"><a href="#Spark生态系统" class="headerlink" title="Spark生态系统"></a>Spark生态系统</h3><p>在我们开始谈<a href="http://lib.csdn.net/base/mongodb" target="_blank" rel="noopener">MongoDB</a> 和Spark 之前，我们首先来了解一下Spark的生态系统。 Spark 作为一个大型分布式计算框架，需要和其他组件一起协同工作。</p>
<p><img src="http://img1.tuicool.com/3uQ7j2J.png!web" alt="img"></p>
<p>在Hdaoop里面，HDFS是其核心，作为一个数据层。</p>
<p>Spark是<a href="http://lib.csdn.net/base/hadoop" target="_blank" rel="noopener">Hadoop</a>生态系统的一颗新星，原生就支持HDFS。大家知道HDFS是用来管理大规模非结构化数据的存储系统，具有高可用和巨大的横向扩展能力。</p>
<p>而作为一个横向扩展的分布式集群，资源管理是其核心必备的能力，Spark 可以通过YARN或者MESOS来负责资源（CPU）分配和任务调度。如果你不需要管理节点的高可用需求，你也可以直接使用Spark standalone。</p>
<p>在有了数据层和资源管理层后， 接下来就是我们真正的计算引擎。</p>
<p><a href="http://lib.csdn.net/base/hadoop" target="_blank" rel="noopener">hadoop</a>技术的两大基石之一的MapReduce就是用来实现集群大规模并行计算。而现在就多了一个选项：Spark。 Map Reduce的特点是，用4个字来概括，简单粗暴。采用divide &amp; conquer战术，我们可以用Map Reduce来处理PB级的数据。 而Spark 作为打了鸡血的Map Reduce增强版，利用了内存价格大量下降的时代因素，充分把计算所用变量和中间结果放到内存里，并且提供了一整套机器学习的分析<a href="http://lib.csdn.net/base/datastructure" target="_blank" rel="noopener">算法</a>，在加上很多语言的支持，使之成为一个较之于Map Reduce更加优秀的选择。</p>
<p>由于Map Reduce 是一个相对并不直观的程序接口，所以为了方便使用，一系列的高层接口如<a href="http://lib.csdn.net/base/hive" target="_blank" rel="noopener">Hive</a>或者Pig应运而生。 <a href="http://lib.csdn.net/base/hive" target="_blank" rel="noopener">hive</a>可以让我们使用非常熟悉的SQL语句的方式来做一些常见的统计分析工作。同理，在Spark 引擎层也有类似的封装，如Spark SQL、RDD以及2.0版本新推出的Dataframe等。</p>
<p>所以一个完整的<a href="http://lib.csdn.net/base/hadoop" target="_blank" rel="noopener">大数据</a>解决方案，包含了存储，资源管理，计算引擎及接口层。 那么问题来了：我们画了这么大这么圆的大饼，<a href="http://lib.csdn.net/base/mongodb" target="_blank" rel="noopener">mongodb</a>可以吃哪一块呢？</p>
<p><img src="http://img1.tuicool.com/rYbm63Q.png!web" alt="img"></p>
<p>MongoDB是个什么？是个database。 所以自然而然，MongoDB可以担任的角色，就是数据存储的这一部分。在和 Spark一起使用的时候，MongoDB就可以扮演HDFS的角色来为Spark提供计算的原始数据，以及用来持久化分析计算的结果。</p>
<h3 id="HDFS-vs-MongoDB"><a href="#HDFS-vs-MongoDB" class="headerlink" title="HDFS vs. MongoDB"></a>HDFS vs. MongoDB</h3><p>既然我们说MongoDB可以用在HDFS的地方，那我们来详细看看两者之间的差异性。</p>
<p>在说区别之前，其实我们可以先来注意一下两者的共同点。HDFS和MongoDB都是基于廉价x86服务器的横向扩展<a href="http://lib.csdn.net/base/architecture" target="_blank" rel="noopener">架构</a>，都能支持到TB到PB级的数据量。数据会在多节点自动备份，来保证数据的高可用和冗余。两者都支持非结构化数据的存储，等等。</p>
<p>但是，HDFS和MongoDB更多的是差异点：</p>
<ul>
<li>如在存储方式上 HDFS的存储是以文件为单位，每个文件64MB到128MB不等。而MongoDB则是细颗粒化的、以文档为单位的存储。</li>
<li>HDFS不支持索引的概念，对数据的操作局限于扫描性质的读，MongoDB则支持基于二级索引的快速检索。</li>
<li>MongoDB可以支持常见的增删改查场景，而HDFS一般只是一次写入后就很难进行修改。</li>
<li>从响应时间上来说，HDFS一般是分钟级别而MongoDB对手请求的响应时间通常以毫秒作为单位。</li>
</ul>
<h3 id="一个日志的例子"><a href="#一个日志的例子" class="headerlink" title="一个日志的例子"></a>一个日志的例子</h3><p>如果说刚才的比较有些抽象，我们可以结合一个实际一点的例子来理解。</p>
<p>比如说，一个比较经典的案例可能是日志记录管理。在HDFS里面你可能会用日期范围来命名文件，如7月1日，7月2日等等，每个文件是个日志文本文件，可能会有几万到几十万行日志。</p>
<p>而在MongoDB里面，我们可以采用一个JSON的格式，每一条日志就是一个JSON document。我们可以对某几个关心的字段建索引，如时间戳，错误类型等。</p>
<p>我们来考虑一些场景，加入我们相对7月份所有日志做一些全量的统计，比如每个页面的所有点击量，那么这个HDFS和MongoDB都可以正常处理。</p>
<p>如果有一天你的经理告诉你：他想知道网站上每天有多少404错误在发生，这个时候如果你用HDFS，就还是需要通过全量扫描所有行，而MongoDB则可以通过索引，很快地找到所有的404日志，可能花数秒钟就可以解答你经理的问题。</p>
<p>又比如说，如果你希望对每个日志项加一个自定义的属性，在进行一些预处理后，MongoDB就会比较容易地支持到。而一般来说，HDFS是不支持更新类型操作的。</p>
<p>好的，我们了解了MongoDB为什么可以替换HDFS并且为什么有这个必要来做这个事情，下面我们就来看看Spark和MongoDB怎么玩！</p>
<h2 id="Spark-MongoDB"><a href="#Spark-MongoDB" class="headerlink" title="Spark + MongoDB"></a>Spark + MongoDB</h2><p>Spark的工作流程可以概括为三部曲：创建并发任务，对数据进行transformation操作，如map， filter，union，intersect等，然后执行运算，如reduce，count，或者简单地收集结果。</p>
<p><img src="http://img1.tuicool.com/jEne2qF.png!web" alt="img"></p>
<p>这里是Spark和MongoDB部署的一个典型架构。</p>
<p>Spark任务一般由Spark的driver节点发起，经过Spark Master进行资源调度分发。比如这里我们有4个Spark worker节点，这些节点上的几个executor 计算进程就会同时开始工作。一般一个core就对应一个executor。</p>
<p>每个executor会独立的去MongoDB取来原始数据，直接套用Spark提供的分析算法或者使用自定义流程来处理数据，计算完后把相应结果写回到MongoDB。</p>
<p>我们需要提到的是：在这里，所有和MongoDB的交互都是通过一个叫做Mongo-Spark的连接器来完成的。</p>
<p><img src="http://img0.tuicool.com/ZNb2Yz3.png!web" alt="img"></p>
<p>另一种常见的架构是结合MongoDB和HDFS的。Hadoop在非结构化数据处理的场景下要比MongoDB的普及率高。所以我们可以看到不少用户会已经将数据存放在HDFS上。这个时候你可以直接在HDFS上面架Spark来跑，Spark从HDFS取来原始数据进行计算，而MongoDB在这个场景下是用来保存处理结果。为什么要这么麻烦？几个原因：</p>
<ul>
<li>Spark处理结果数量可能会很大，比如说，个性化推荐可能会产生数百万至数千万条记录，需要一个能够支持每秒万级写入能力的数据库</li>
<li>处理结果可以直接用来驱动前台APP，如用户打开页面时获取后台已经为他准备好的推荐列表。</li>
</ul>
<h3 id="Mongo-Spark-Connector-连接器"><a href="#Mongo-Spark-Connector-连接器" class="headerlink" title="Mongo Spark Connector 连接器"></a>Mongo Spark Connector 连接器</h3><p>在这里我们在介绍下MongoDB官方提供的 <a href="https://github.com/mongodb/mongo-spark" target="_blank" rel="noopener">Mongo Spark连接器</a> 。目前有3个连接器可用，包括社区第三方开发的和之前Mongo Hadoop连接器等，这个Mongo-Spark是最新的，也是我们推荐的连接方案。</p>
<p><img src="http://img1.tuicool.com/nyMj2a2.png!web" alt="img"></p>
<p>这个连接器是专门为Spark打造的，支持双向数据，读出和写入。但是最关键的是 条件下推 ，也就是说：如果你在Spark端指定了查询或者限制条件的情况下，这个条件会被下推到MongoDB去执行，这样可以保证从MongoDB取出来、经过网络传输到Spark计算节点的数据确实都是用得着的。没有下推支持的话，每次操作很可能需要从MongoDB读取全量的数据，性能体验将会很糟糕。拿刚才的日志例子来说，如果我们只想对404错误日志进行分析，看那些错误都是哪些页面，以及每天错误页面数量的变化，如果有条件下推，那么我们可以给MongoDB一个限定条件：错误代码=404， 这个条件会在MongoDB服务器端执行，这样我们只需要通过网络传输可能只是全部日志的0.1%的数据，而不是没有条件下推情况下的全部数据。</p>
<p>另外，这个最新的连接器还支持和Spark计算节点Co-Lo 部署。就是说在同一个节点上同时部署Spark实例和MongoDB实例。这样做可以减少数据在网络上的传输带来的资源消耗及时延。当然，这种部署方式需要注意内存资源和CPU资源的隔离。隔离的方式可以通过Linux的cgroups。</p>
<h2 id="Spark-MongoDB-成功案例"><a href="#Spark-MongoDB-成功案例" class="headerlink" title="Spark + MongoDB 成功案例"></a>Spark + MongoDB 成功案例</h2><p>目前已经有很多案例在不同的应用场景中使用Spark+MongoDB。</p>
<p>法国航空是法国最大的航空公司，为了提高客户体验，在最近施行的360度客户视图中，使用Spark对已经收集在MongoDB里面的客户数据进行分类及行为分析，并把结果（如客户的类别、标签等信息）写回到MongoDB内每一个客户的文档结构里。</p>
<p>Stratio是美国硅谷一家著名的金融大数据公司。他们最近在一家在31个国家有分支机构的跨国银行实施了一个实时监控平台。该银行希望通过对日志的监控和分析来保证客户服务的响应时间以及实时监测一些可能的违规或者金融欺诈行为。在这个应用内， 他们使用了：</p>
<p>Stratio是美国硅谷一家著名的金融大数据公司。他们最近在一家在31个国家有分支机构的跨国银行实施了一个实时监控平台。该银行希望通过对日志的监控和分析来保证客户服务的响应时间以及实时监测一些可能的违规或者金融欺诈行为。在这个应用内， 他们使用了：</p>
<ul>
<li>Apache Flume 来收集log</li>
<li>Spark来处理实时的log</li>
<li>MongoDB来存储收集的log以及Spark分析的结果，如Key Performance Indicators等</li>
</ul>
<p>东方航空最近刚完成一个Spark运价的POC测试。</p>
<h3 id="东方航空的挑战"><a href="#东方航空的挑战" class="headerlink" title="东方航空的挑战"></a>东方航空的挑战</h3><p>东方航空作为国内的3大行之一，每天有1000多个航班，服务26万多乘客。过去，顾客在网站上订购机票，平均资料库查询200次就会下单订购机票，但是现在平均要查询1.2万次才会发生一次订购行为，同样的订单量，查询量却成长百倍。按照50%直销率这个目标计算，东航的运价系统要支持每天16亿的运价请求。</p>
<h3 id="思路：空间换时间"><a href="#思路：空间换时间" class="headerlink" title="思路：空间换时间"></a>思路：空间换时间</h3><p>当前的运价是通过实时计算的，按照现在的计算能力，需要对已有系统进行100多倍的扩容。另一个常用的思路，就是采用空间换时间的方式。与其对每一次的运价请求进行耗时300ms的运算，不如事先把所有可能的票价查询组合穷举出来并进行批量计算，然后把结果存入MongoDB里面。当需要查询运价时，直接按照 出发+目的地+日期的方式做一个快速的DB查询，响应时间应该可以做到几十毫秒。</p>
<p>那为什么要用MongoDB？因为我们要处理的数据量庞大无比。按照1000多个航班，365天，26个仓位，100多渠道以及数个不同的航程类型，我们要实时存取的运价记录有数十亿条之多。这个已经远远超出常规RDBMS可以承受的范围。</p>
<p>MongoDB基于内存缓存的数据管理方式决定了对并发读写的响应可以做到很低延迟，水平扩展的方式可以通过多台节点同时并发处理海量请求。</p>
<p>事实上，全球最大的航空分销商，管理者全世界95%航空库存的Amadeus也正是使用MongoDB作为其1000多亿运价缓存的存储方案。</p>
<h3 id="Spark-MongoDB-方案"><a href="#Spark-MongoDB-方案" class="headerlink" title="Spark + MongoDB 方案"></a>Spark + MongoDB 方案</h3><p>我们知道MongoDB可以用来做我们海量运价数据的存储方案，在大规模并行计算方案上，就可以用到崭新的Spark技术。</p>
<p><img src="http://img0.tuicool.com/rUjuYv.png!web" alt="img"></p>
<p>这里是一个运价系统的架构图。 左边是发起航班查询请求的客户端，首先会有API服务器进行预处理。一般航班请求会分为库存查询和运价查询。库存查询会直接到东航已有的库存系统（Seat Inventory），同样是实现在MongoDB上面的。在确定库存后根据库存结果再从Fare Cache系统内查询相应的运价。</p>
<p>Spark集群则是另外一套计算集群，通过Spark MongoDB连接套件和MongoDB Fare Cache集群连接。Spark 计算任务会定期触发（如每天一次或者每4小时一次），这个任务会对所有的可能的运价组合进行全量计算，然后存入MongoDB，以供查询使用。右半边则把原来实时运算的集群换成了Spark+MongoDB。Spark负责批量计算一年内所有航班所有仓位的所有价格，并以高并发的形式存储到MongoDB里面。每秒钟处理的运价可以达到数万条。</p>
<p>当来自客户端的运价查询达到服务端以后，服务端直接就向MongoDB发出按照日期，出发到达机场为条件的mongo查询。</p>
<h3 id="批处理计算流程"><a href="#批处理计算流程" class="headerlink" title="批处理计算流程"></a>批处理计算流程</h3><p><img src="http://img2.tuicool.com/MNruymF.png!web" alt="img"></p>
<p>这里是Spark计算任务的流程图。需要计算的任务，也就是所有日期航班仓位的组合，事先已经存放到MongoDB里面。</p>
<p>任务递交到master，然后预先加载所需参考数据，broadcast就是把这些在内存里的数据复制到每一个Spark计算节点的JVM，然后所有计算节点多线程并发执行，从Mongodb里取出需要计算的仓位，调用东航自己的运价逻辑，得出结果以后，并保存回MongoDB。</p>
<h3 id="Spark-任务入口程序"><a href="#Spark-任务入口程序" class="headerlink" title="Spark 任务入口程序"></a>Spark 任务入口程序</h3><p>Spark和MongoDB的连接使用非常简单，下面就是一个代码示例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">// initialization dependencies including base prices, pricing rules and some reference data</span><br><span class="line">Map dependencies = MyDependencyManager.loadDependencies();</span><br><span class="line">// broadcasting dependencies</span><br><span class="line">javaSparkContext.broadcast(dependencies);</span><br><span class="line"></span><br><span class="line">// create job rdd</span><br><span class="line">cabinsRDD = MongoSpark.load(javaSparkContext).withPipeline(pipeline)</span><br><span class="line"></span><br><span class="line">// for each cabin, date, airport pair, calculate the price</span><br><span class="line">cabinsRDD.map(function calc_price);</span><br><span class="line"></span><br><span class="line">// collect the result, which will cause the data to be stored into MongoDB</span><br><span class="line">cabinsRDD.collect()</span><br><span class="line">cabinsRDD.saveToMongo()</span><br></pre></td></tr></table></figure>
<h3 id="处理能力和响应时间比较"><a href="#处理能力和响应时间比较" class="headerlink" title="处理能力和响应时间比较"></a>处理能力和响应时间比较</h3><p>这里是一个在东航POC的简单测试结果。从吞吐量的角度，新的API服务器单节点就可以处理3400个并发的运价请求。在显著提高了并发的同时，响应延迟则降低了10几倍，平均10ms就可以返回运价结果。按照这个性能，6台 API服务器就可以应付将来每天16亿的运价查询。</p>
<p><img src="http://img0.tuicool.com/3u6fqe.png!web" alt="img"></p>
<h2 id="Spark-＋-MongoDB-演示"><a href="#Spark-＋-MongoDB-演示" class="headerlink" title="Spark ＋ MongoDB 演示"></a>Spark ＋ MongoDB 演示</h2><p>接下来是一个简单的Spark+MongoDB演示。</p>
<h3 id="安装-Spark"><a href="#安装-Spark" class="headerlink" title="安装 Spark"></a>安装 Spark</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># curl -OL http://d3kbcqa49mib13.cloudfront.net/spark-1.6.0-bin-hadoop2.6.tgz</span><br><span class="line"># mkdir -p ~/spark</span><br><span class="line"># tar -xvf spark-1.6.0-bin-hadoop2.6.tgz -C ~/spark --strip-components=1</span><br></pre></td></tr></table></figure>
<h3 id="测试连接器"><a href="#测试连接器" class="headerlink" title="测试连接器"></a>测试连接器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># cd ～／spark</span><br><span class="line"># ./bin/spark-shell \</span><br><span class="line">--conf &quot;spark.mongodb.input.uri=mongodb://127.0.0.1/flights.av&quot; \</span><br><span class="line">--conf &quot;spark.mongodb.output.uri=mongodb://127.0.0.1/flights.output&quot; \</span><br><span class="line">--packages org.mongodb.spark:mongo-spark-connector_2.10:1.0.0</span><br><span class="line"></span><br><span class="line">import com.mongodb.spark._</span><br><span class="line">import org.bson.Document</span><br><span class="line"></span><br><span class="line">MongoSpark.load(sc).take(10).foreach(println)</span><br></pre></td></tr></table></figure>
<h3 id="简单分组统计"><a href="#简单分组统计" class="headerlink" title="简单分组统计"></a>简单分组统计</h3><p>数据： 365天，所有航班库存信息，500万文档</p>
<p>任务： 按航班统计一年内所有余票量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MongoSpark.load(sc)</span><br><span class="line">     .map(doc=&gt;(doc.getString(&quot;flight&quot;) ,doc.getLong(&quot;seats&quot;)))</span><br><span class="line">     .reduceByKey((x,y)=&gt;(x+y))</span><br><span class="line">      .take(10)</span><br><span class="line">     .foreach(println)</span><br></pre></td></tr></table></figure>
<h3 id="简单分组统计加条件过滤"><a href="#简单分组统计加条件过滤" class="headerlink" title="简单分组统计加条件过滤"></a>简单分组统计加条件过滤</h3><p>数据： 365天，所有航班库存信息，500万文档</p>
<p>任务： 按航班统计一年内所有库存，但是只处理昆明出发的航班</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import org.bson.Document</span><br><span class="line"></span><br><span class="line">MongoSpark.load(sc)</span><br><span class="line">          .withPipeline(Seq(Document.parse(&quot;&#123; $match: &#123; orig :  &apos;KMG&apos;  &#125; &#125;&quot;)))</span><br><span class="line">    .map(doc=&gt;(doc.getString(&quot;flight&quot;) ,doc.getLong(&quot;seats&quot;)))</span><br><span class="line">    .reduceByKey((x,y)=&gt;(x+y))</span><br><span class="line">    .take(10)</span><br><span class="line">    .foreach(println)</span><br></pre></td></tr></table></figure>
<h3 id="性能优化事项"><a href="#性能优化事项" class="headerlink" title="性能优化事项"></a>性能优化事项</h3><ul>
<li>使用合适的chunksize (MB)<br>Total data size / chunksize = chunks = RDD partitions = spark tasks</li>
<li>不要将所有CPU核分配给Spark<br>预留1-2个core给操作系统及其他管理进程</li>
<li>同机部署<br>适当情况可以同机部署Spark+MongoDB，利用本地IO提高性能</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面只是一些简单的演示，实际上Spark + MongoDB的使用可以通过Spark的很多种形式来使用。我们来总结一下Spark ＋ Mongo的应用场景。在座的同学可能很多人已经使用了MongoDB，也有些人已经使用了Hadoop。我们可以从两个角度来考虑这个事情：</p>
<ul>
<li>对那些已经使用MongoDB的用户，如果你希望在你的MongoDB驱动的应用上提供个性化功能，比如说像Yahoo一样为你找感兴趣的新闻，能够在你的MongoDB数据上利用到Spark强大的机器学习或者流处理，你就可以考虑在MongoDB集群上部署Spark来实现这些功能。</li>
<li>如果你已经使用Hadoop而且数据已经在HDFS里面，你可以考虑使用Spark来实现更加实时更加快速的分析型需求，并且如果你的分析结果有数据量大、格式多变以及这些结果数据要及时提供给前台APP使用的需求，那么MongoDB可以用来作为你分析结果的一个存储方案。</li>
</ul>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/07/23/Oracle备份的概念和术语/" itemprop="url">Oracle备份的概念和术语</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-07-23T04:25:37.000Z" itemprop="datePublished">1 年前</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Technology/">Technology</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            4 分钟 读完 (约 584 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>Oracle备份是Oracle运维工作中非常重要的一个环节。Oracle备份的概念比较多，容易引起混淆。下面就具体概念和术语进行一个简单的辨析。</p>
<h1 id="概念辨析"><a href="#概念辨析" class="headerlink" title="概念辨析"></a>概念辨析</h1><ol>
<li>用操作系统命令执行的备份被称为<strong>用户管理备份</strong>。使用RMAN执行的备份被称为<strong>服务器管理的备份</strong>。</li>
<li>关闭状态的备份在数据库关闭期间执行，也称为<strong>冷备份、一致备份或脱机备份</strong>。打开状态的备份在数据库使用期间执行，也称为<strong>热备份、非一致备份或联机备份</strong>。</li>
<li>打开状态的备份只能在数据库处于<strong>归档日志模式</strong>下才能进行。</li>
<li><strong>全部备份</strong>指的是备份所有数据文件和控制文件。<strong>局部备份</strong>只备份其子集。在大部分情况下，局部备份只能在数据库处于<strong>归档日志模式</strong>下才能进行。</li>
<li><strong>完整备份</strong>备份所有使用的文件块。<strong>增量备份</strong>只包括自上次备份以来更改的块。</li>
<li>增量备份可以是累积增量备份或差异增量备份。<strong>累积增量备份</strong>指自上一次完整备份以来更改的所有块。<strong>差异增量备份</strong>指自上一次增量备份以来更改的所有块。</li>
</ol>
<h1 id="使用RMAN-Backup命令创建备份"><a href="#使用RMAN-Backup命令创建备份" class="headerlink" title="使用RMAN Backup命令创建备份"></a>使用RMAN Backup命令创建备份</h1><h2 id="1-服务器管理的一致备份"><a href="#1-服务器管理的一致备份" class="headerlink" title="1.服务器管理的一致备份"></a>1.服务器管理的一致备份</h2><p>RMAN备份脚本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">run &#123;                                                                                 </span><br><span class="line">shutdown immediate;                                                                   </span><br><span class="line">startup mount;                                                                       </span><br><span class="line">allocate channel d1 type disk;                                                      </span><br><span class="line">backup as backupset database format &apos;/home/oracle/Documents/offline_full_whole%U.bus&apos;;</span><br><span class="line">alter database open;                                                     </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用RMAN运行一致性备份：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rman target sys/密码@orcl @/home/oracle/Documents/offline_all.rman</span><br></pre></td></tr></table></figure>
<p>如果遇到报错，可以按照如下方式进行处理：</p>
<p>[linuxidc@rhel55 ~]$rman target sys/<a href="http://www.linuxidc.com/topicnews.aspx?tid=12" target="_blank" rel="noopener">Oracle</a>@orcl</p>
<p>ORA-12514: TNS:listener does not currently know of service requested in connect descriptor<br>[linuxidc@rhel55 ~]$lsnrctl stop</p>
<p>[linuxidc@rhel55 ~]$cd $ORACLE_HOME</p>
<p>[linuxidc@rhel55 db_1]$vim listener.ora</p>
<p>修改/u01/app/oracle/product/11.2.0/db_1/network/admin/listener.ora文件<br>加上<br>SID_LIST_LISTENER =<br>  (SID_LIST =<br>    (SID_DESC =<br>      (SID_NAME = orcl)<br>      (ORACLE_HOME = /u01/app/oracle/product/11.2.0/db_1)<br>    )<br>  )<br>然后重启lisener服务，就ok了</p>
<p>[linuxidc@rhel55 ~]$lsnrctl start</p>
<h2 id="2-服务器管理的打开状态的备份"><a href="#2-服务器管理的打开状态的备份" class="headerlink" title="2. 服务器管理的打开状态的备份"></a>2. 服务器管理的打开状态的备份</h2><p>使用BACKUP命令执行绝对可靠的打开备份。</p>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/07/15/数据湖架构的核心原则/" itemprop="url">数据湖架构的核心原则</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-07-15T03:12:25.000Z" itemprop="datePublished">1 年前</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Technology/">Technology</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            3 分钟 读完 (约 460 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>以下 内容摘自《企业数据湖》第三章</p>
<ul>
<li>数据以原始格式（不可变数据）进入数据湖。企业中的所有数据都有价值。不要试图在第一时间获得价值，而只是摄取数据，然后再尝试从中挖掘价值。</li>
<li>在数据摄取期间，不用急于挖掘价值。</li>
<li>准备好接受多种类型的数据（结构化和非结构化的数据）</li>
<li>准备好接受各种数量级的数据。</li>
<li>不要限制数据存储，这样用户可以在数据湖中查询数据。根据需求引入各种技术，来进行各种分析。</li>
<li>为企业应用程序访问数据提供简单的方法。最终这些数据没有太大意义，但一段时间后，这些数据便能够与数据湖中的其他数据元素协作，并为企业带来价值。</li>
<li>存储时无须对数据进行标准化处理。</li>
<li>能够快速、简单且低成本（高度可伸缩）地添加数据源。</li>
<li>能够根据消费需求提供各种格式的企业数据给应用程序使用。</li>
<li>能够通过数据聚合和大规模数据处理来支持数据智能需求。</li>
<li>能够在系统运行或空闲时清理数据。</li>
<li>能够支持各种安全机制。</li>
<li>由于需要提供重要的企业数据，因而必须高度可用。</li>
<li>不要强制改变进入数据的格式，而是以传入数据的格式来接收数据。</li>
<li>尽可能减少数据量和网络带宽需求。通过使用多种压缩方法来实现这一点。</li>
</ul>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/06/11/TensorFlow实战（一）：简单示例/" itemprop="url">TensorFlow实战（一）：简单示例</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-06-11T07:28:30.000Z" itemprop="datePublished">2 年前</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Technology/">Technology</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            2 分钟 读完 (约 362 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>本文是TensorFlow实战的开篇，请确认好您已经安装好Python3开发环境，并安装设置好NumPy、matplotlib、TensorFlow和Jupyter Notebook。</p>
<h1 id="软件介绍"><a href="#软件介绍" class="headerlink" title="软件介绍"></a>软件介绍</h1><h2 id="Jupyter-Notebook"><a href="#Jupyter-Notebook" class="headerlink" title="Jupyter Notebook"></a>Jupyter Notebook</h2><h2 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h2><p>matplotlib是一个绘图库，它允许用户使用Python创绩动态的、自定义的可视化结果。它与Numpy无缝集成，其绘图结果可直接显示在Jupyter Notebook中。matplotlib也可将数值以图像的形式可视化，这个功能可用于验证图像识别任务的输出，并将神经网络的内部单元可视化。构建在matplotlib之上的其它层，如Seaborn，可用于增强其功能。</p>
<h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><h1 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h1><p>以下代码可以运行在Jupyter Notebook中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">a= tf.random_normal([<span class="number">2</span>,<span class="number">20</span>])</span><br><span class="line">sess=tf.Session()</span><br><span class="line">out=sess.run(a)</span><br><span class="line">x,y=out</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>成功运行如下图：</p>
<img src="/2019/06/11/TensorFlow实战（一）：简单示例/python.png" title="运行示例">
<p>我们逐条讲解代码：</p>
<ol>
<li>用TensorFlow定义一个由随机数组成的2*20矩阵，比将其赋给变量a。</li>
<li>启动tensorFlow Session，并将其赋给一个sess对象。</li>
<li>用sess.run()方法执行对象a，并将输出（NumPy数组）赋给out。</li>
<li>将这个2<em>20的矩阵划分成为两个1 </em>10的向量x和y。</li>
<li>利用pyplot模块绘制散点图，x对应横轴，y对应纵轴。</li>
</ol>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/04/29/CentOS-7-部署Ceph集群/" itemprop="url">CentOS 7 部署Ceph集群</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-04-29T01:38:00.000Z" itemprop="datePublished">2 年前</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Technology/">Technology</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            5 分钟 读完 (约 803 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>#三、部署集群</p>
<h4 id="1-安装准备，创建文件夹"><a href="#1-安装准备，创建文件夹" class="headerlink" title="1. 安装准备，创建文件夹"></a>1. 安装准备，创建文件夹</h4><p>在管理节点上创建一个目录，用于保存 ceph-deploy 生成的配置文件和密钥对。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cd ~</span><br><span class="line">$ mkdir my-cluster</span><br><span class="line">$ cd my-cluster</span><br></pre></td></tr></table></figure>
<p><strong>注：若安装ceph后遇到麻烦可以使用以下命令进行清除包和配置：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 删除安装包</span><br><span class="line">$ ceph-deploy purge admin-node node1 node2 node3</span><br><span class="line"></span><br><span class="line">// 清除配置</span><br><span class="line">$ ceph-deploy purgedata admin-node node1 node2 node3</span><br><span class="line">$ ceph-deploy forgetkeys</span><br></pre></td></tr></table></figure>
<h4 id="2-创建集群和监控节点"><a href="#2-创建集群和监控节点" class="headerlink" title="2. 创建集群和监控节点"></a>2. 创建集群和监控节点</h4><p>创建集群并初始化<strong>监控节点</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ceph-deploy new &#123;initial-monitor-node(s)&#125;</span><br></pre></td></tr></table></figure>
<p>这里node1是monitor节点，所以执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ceph-deploy new ceph_node1</span><br></pre></td></tr></table></figure>
<p>完成后，my-clster 下多了3个文件：<code>ceph.conf</code>、<code>ceph-deploy-ceph.log</code> 和 <code>ceph.mon.keyring</code>。</p>
<blockquote>
<ul>
<li>问题：如果出现 “[ceph_deploy][ERROR ] RuntimeError: remote connection got closed, ensure <code>requiretty</code> is disabled for node1”，执行 sudo visudo 将 Defaults requiretty 注释掉。</li>
</ul>
</blockquote>
<h4 id="3-修改配置文件"><a href="#3-修改配置文件" class="headerlink" title="3. 修改配置文件"></a>3. 修改配置文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat ceph.conf</span><br></pre></td></tr></table></figure>
<p>内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">fsid = 2539e16a-2b19-476d-8005-3d749e288583</span><br><span class="line">mon_initial_members = ceph_node1</span><br><span class="line">mon_host = 10.10.20.61</span><br><span class="line">auth_cluster_required = cephx</span><br><span class="line">auth_service_required = cephx</span><br><span class="line">auth_client_required = cephx</span><br><span class="line">osd pool default size = 2</span><br><span class="line">rbd_default_features = 1</span><br></pre></td></tr></table></figure>
<p>把 Ceph 配置文件里的默认副本数从 3 改成 2 ，这样只有两个 OSD 也可以达到 active + clean 状态。把 osd pool default size = 2 加入 [global] 段：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sed -i &apos;$a\osd pool default size = 2&apos; ceph.conf</span><br></pre></td></tr></table></figure>
<p>如果有多个网卡，<br>可以把 public network 写入 Ceph 配置文件的 [global] 段：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public network = &#123;ip-address&#125;/&#123;netmask&#125;</span><br></pre></td></tr></table></figure>
<p>如果Ceph存储需要提供kubernetes使用的OSD，注意要设置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd_default_features = 1</span><br></pre></td></tr></table></figure>
<h4 id="4-安装Ceph"><a href="#4-安装Ceph" class="headerlink" title="4. 安装Ceph"></a>4. 安装Ceph</h4><p>在所有节点上安装ceph：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ceph-deploy install ceph_admin_node ceph_node1 ceph_node2 ceph_node3 ceph_node4</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>问题：[ceph_deploy][ERROR ] RuntimeError: Failed to execute command: yum -y install epel-release</li>
</ul>
<p>解决方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; sudo yum -y remove epel-release</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<h4 id="5-配置初始-monitor-s-、并收集所有密钥"><a href="#5-配置初始-monitor-s-、并收集所有密钥" class="headerlink" title="5. 配置初始 monitor(s)、并收集所有密钥"></a>5. 配置初始 monitor(s)、并收集所有密钥</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ceph-deploy mon create-initial</span><br></pre></td></tr></table></figure>
<p>完成上述操作后，当前目录里应该会出现这些密钥环：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;cluster-name&#125;.client.admin.keyring</span><br><span class="line">&#123;cluster-name&#125;.bootstrap-osd.keyring</span><br><span class="line">&#123;cluster-name&#125;.bootstrap-mds.keyring</span><br><span class="line">&#123;cluster-name&#125;.bootstrap-rgw.keyring</span><br></pre></td></tr></table></figure>
<h4 id="6-添加OSD"><a href="#6-添加OSD" class="headerlink" title="6. 添加OSD"></a>6. 添加OSD</h4><p>1) 登录到 Ceph 节点、并给 OSD 守护进程创建一个目录，并添加权限。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ ssh node1</span><br><span class="line">$ sudo mkdir /var/local/osd1</span><br><span class="line">$ sudo chmod 777 /var/local/osd1/</span><br><span class="line">$ exit</span><br><span class="line"></span><br><span class="line">$ ssh node2</span><br><span class="line">$ sudo mkdir /var/local/osd2</span><br><span class="line">$ sudo chmod 777 /var/local/osd2/</span><br><span class="line">$ exit</span><br></pre></td></tr></table></figure>
<p>注意，从最好将osd单独做一个分区，log单独做一个分区。其中osd分区使用xfs格式，这是ceph最佳推荐设置。</p>
<p>我是用了linux lvm，LV名称为/dev/data/osd</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ceph]# mkfs.xfs -f /dev/data/osd</span><br><span class="line">meta-data=/dev/data/osd          isize=256    agcount=4, agsize=32761600 blks</span><br><span class="line">         =                       sectsz=512   attr=2, projid32bit=1</span><br><span class="line">         =                       crc=0        finobt=0</span><br><span class="line">data     =                       bsize=4096   blocks=131046400, imaxpct=25</span><br><span class="line">         =                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=0</span><br><span class="line">log      =internal log           bsize=4096   blocks=63987, version=2</span><br><span class="line">         =                       sectsz=512   sunit=0 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br><span class="line">[root@localhost ceph]# mount -t xfs /dev/data/osd /var/local/osd4</span><br><span class="line">[root@localhost ceph]# df -Th</span><br><span class="line">文件系统                类型      容量  已用  可用 已用% 挂载点</span><br><span class="line">/dev/mapper/centos-root xfs        50G  1.7G   49G    4% /</span><br><span class="line">devtmpfs                devtmpfs  7.8G     0  7.8G    0% /dev</span><br><span class="line">tmpfs                   tmpfs     7.8G     0  7.8G    0% /dev/shm</span><br><span class="line">tmpfs                   tmpfs     7.8G  8.6M  7.8G    1% /run</span><br><span class="line">tmpfs                   tmpfs     7.8G     0  7.8G    0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-home xfs        42G   33M   42G    1% /home</span><br><span class="line">/dev/sda1               xfs       497M  124M  373M   25% /boot</span><br><span class="line">tmpfs                   tmpfs     1.6G     0  1.6G    0% /run/user/0</span><br><span class="line">/dev/mapper/data-osd    xfs       500G   33M  500G    1% /var/local/osd4</span><br></pre></td></tr></table></figure>
<p>2) 然后，从管理节点执行 ceph-deploy 来准备 OSD 。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ceph-deploy osd prepare node2:/var/local/osd0 node3:/var/local/osd1</span><br></pre></td></tr></table></figure>
<p>3) 最后，激活 OSD 。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ceph-deploy osd activate node2:/var/local/osd0 node3:/var/local/osd1</span><br></pre></td></tr></table></figure>
    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/04/24/ORA-00257-归档程序错误。在释放之前仅限于内部连接/" itemprop="url">ORA-00257: 归档程序错误。在释放之前仅限于内部连接</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-04-24T12:41:58.000Z" itemprop="datePublished">2 年前</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Technology/">Technology</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            4 分钟 读完 (约 605 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>由于近期全国测绘统计年报进入集中上报阶段，造成数据库压力过大，且频繁的数据读写造成数据库归档日志增长非常快，月初才清理的归档日志空间已满，造成数据库报错。</p>
<p>错误提示：<code>ORA-00257: 归档程序错误。在释放之前仅限于内部连接</code></p>
<p>Oracle数据库版本：<code>Oracle 11g R2</code></p>
<p>这是Oracle数据库较为常见的一类错误，错误原因是数据库归档日志已满，造成数据库无法提供服务。处理方案就是扩大归档日志空间并且使用RMAN清理已有的归档日志。</p>
<p>操作步骤：</p>
<ol>
<li><p>从服务器本地登录数据库：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Microsoft Windows [版本 6.1.7601]</span><br><span class="line">版权所有 (c) 2009 Microsoft Corporation。保留所有权利。</span><br><span class="line"></span><br><span class="line">C:\Users\Administrator&gt;sqlplus / as sysdba</span><br><span class="line"></span><br><span class="line">SQL*Plus: Release 11.2.0.1.0 Production on 星期三 4月 24 20:10:13 2019</span><br><span class="line"></span><br><span class="line">Copyright (c) 1982, 2010, Oracle.  All rights reserved.</span><br><span class="line"></span><br><span class="line">连接到:</span><br><span class="line">Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - Production</span><br><span class="line">With the Partitioning, OLAP, Data Mining and Real Application Testing options</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询归档日志使用情况：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; select * from v$recovery_file_dest;</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">SPACE_LIMIT SPACE_USED SPACE_RECLAIMABLE NUMBER_OF_FILES</span><br><span class="line">----------- ---------- ----------------- ---------------</span><br><span class="line">D:\app\Administrator\flash_recovery_area</span><br><span class="line"> 1.0737E+10 1.0729E+10                 0             281</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from v$flash_recovery_area_usage;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询归档日志设置大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; show parameter db_recovery_file_dest_size</span><br><span class="line"></span><br><span class="line">NAME                                 TYPE        VALUE</span><br><span class="line">------------------------------------ ----------- ------------------------------</span><br><span class="line">db_recovery_file_dest_size           big integer 10G</span><br></pre></td></tr></table></figure>
</li>
<li><p>扩大归档日志空间设置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; alter system set db_recovery_file_dest_size=20G scope=both;</span><br><span class="line"></span><br><span class="line">系统已更改。</span><br></pre></td></tr></table></figure>
</li>
<li><p>确认设置情况</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; show parameter db_recovery_file_dest_size</span><br><span class="line"></span><br><span class="line">NAME                                 TYPE        VALUE</span><br><span class="line">------------------------------------ ----------- ------------------------------</span><br><span class="line">db_recovery_file_dest_size           big integer 20G</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; select * from v$recovery_file_dest;</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">SPACE_LIMIT SPACE_USED SPACE_RECLAIMABLE NUMBER_OF_FILES</span><br><span class="line">----------- ---------- ----------------- ---------------</span><br><span class="line">D:\app\Administrator\flash_recovery_area</span><br><span class="line"> 2.1475E+10 6496842240                 0             167</span><br></pre></td></tr></table></figure>
</li>
<li><p>进入RMAN</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Microsoft Windows [版本 6.1.7601]</span><br><span class="line">版权所有 (c) 2009 Microsoft Corporation。保留所有权利。</span><br><span class="line"></span><br><span class="line">C:\Users\Administrator&gt;rman target /</span><br><span class="line"></span><br><span class="line">恢复管理器: Release 11.2.0.1.0 - Production on 星期三 4月 24 20:49:42 2019</span><br><span class="line"></span><br><span class="line">Copyright (c) 1982, 2009, Oracle and/or its affiliates.  All rights reserved.</span><br><span class="line"></span><br><span class="line">连接到目标数据库: ORL (DBID=1362993468)</span><br><span class="line"></span><br><span class="line">RMAN&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>找出状态为expired的归档日志 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RMAN&gt;crosscheck   archivelog all;</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除3天前的归档日志，腾出有效空间</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RMAN&gt; DELETE ARCHIVELOG ALL COMPLETED BEFORE &apos;SYSDATE-3&apos;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在plsql界面关闭数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; shutdown abort;</span><br><span class="line">ORACLE 例程已经关闭。</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动并装载数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; startup mount;</span><br><span class="line">ORACLE 例程已经启动。</span><br><span class="line"></span><br><span class="line">Total System Global Area 1732554752 bytes</span><br><span class="line">Fixed Size                  1378008 bytes</span><br><span class="line">Variable Size            1065355560 bytes</span><br><span class="line">Database Buffers          654311424 bytes</span><br><span class="line">Redo Buffers               11509760 bytes</span><br><span class="line">数据库装载完毕。</span><br></pre></td></tr></table></figure>
</li>
<li><p>打开数据库服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; alter database open;</span><br><span class="line"></span><br><span class="line">数据库已更改。</span><br></pre></td></tr></table></figure>
</li>
</ol>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/04/16/关闭mysql的表名库名大小写敏感开关/" itemprop="url">关闭mysql的表名库名大小写敏感开关</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-04-16T06:51:23.000Z" itemprop="datePublished">2 年前</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Technology/">Technology</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            1 分钟 读完 (约 173 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>原来Linux下的MySQL默认是区分表名大小写的，通过如下设置，可以让MySQL不区分表名大小写：<br>1、用root登录，修改 /etc/my.cnf；<br>2、在[mysqld]节点下，加入一行： lower_case_table_names=1<br>3、重启MySQL即可；<br>其中 lower_case_table_names=1 参数缺省地在 Windows 中这个选项为 1 ，在 Unix 中为 0，因此在window中不会遇到的问题，一旦一直到linux就会出问题的原因（尤其在mysql对表起名时是无法用大写字母的，而查询用了大写字母却会出查不到的错误，真是弄的莫名其妙）</p>

    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/04/10/开发常用中间件、数据库的docker快速启动/" itemprop="url">开发常用中间件、数据库的docker快速启动</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-04-10T13:18:55.000Z" itemprop="datePublished">2 年前</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Technology/">Technology</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            几秒 读完 (约 71 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <p>[TOC]</p>
<h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name=orders-mysqldb -d -p 3306:3306 -e MYSQL_ROOT_HOST=% -e MYSQL_ROOT_PASSWORD=root -e MYSQL_USER=orders -e MYSQL_PASSWORD=orders -e MYSQL_DATABASE=orders mysql/mysql-server:5.7.24</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># Redis</span><br><span class="line"></span><br><span class="line">无密码：</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">docker run --name some-redis -p 6379:6379 -d redis redis-server --appendonly yes</span><br></pre></td></tr></table></figure>
<p>带密码：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name some-redis -p 6379:6379 -d redis redis-server --appendonly yes --requirepass "mypassword"</span><br></pre></td></tr></table></figure></p>

    
    </div>
    
    
</article>




    
    
        
<nav class="pagination is-centered is-rounded" role="navigation" aria-label="pagination">
    <div class="pagination-previous">
        <a href="/">上一页</a>
    </div>
    <div class="pagination-next">
        <a href="/page/3/">下一页</a>
    </div>
    <ul class="pagination-list is-hidden-mobile">
        
        <li><a class="pagination-link" href="/">1</a></li>
        
        <li><a class="pagination-link is-current" href="/page/2/">2</a></li>
        
        <li><a class="pagination-link" href="/page/3/">3</a></li>
        
        <li><a class="pagination-link" href="/page/4/">4</a></li>
        
        <li><a class="pagination-link" href="/page/5/">5</a></li>
        
    </ul>
</nav>
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2020 肖飞&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" href="https://github.com/xyfigo">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        //plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {matchFontHeight: false},
        SVG: {matchFontHeight: false},
        CommonHTML: {matchFontHeight: false}
    });
</script>

    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    

    


<script src="/js/script.js"></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="站内搜索">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js"></script>
    
</body>
</html>