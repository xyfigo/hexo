---
title: Minio现代数据湖：第一部分
date: 2018-12-26 10:40:48
tags: Minio
categories: Technology
---

现代数据湖构筑于云存储之上，帮助用户取得扩展性和对象存储经济性的平衡，并简化全部的数据存储和分析流程。

在此系列的第一部分，我们将探讨对象存储与其他存储方式的不同，以及为何对象存储对于数据湖的构建意义重大。

# 什么是对象存储

对象存储泛指一种平台组织存储单元的方式，这种组织方式成为对象。每个对象通常包括以下三部分：

- 数据本身。数据可以是任何想要存储的东西，从一张家庭照片到有40万页的火箭建造指南。
- 数量可扩展的元数据。元数据被创建对象存储的人所定义，它包括描述数据内容的上下文信息、数据的用途、机密性、以及与数据使用方式相关的任何其他内容。
- 全局唯一的标识符。标识符是一个赋予对象的地址，可以通过标识符在分布式系统中找到该对象。用这种方式，能够在不知道其物理地址的情况下找到数据。它可能位于一个数据中心的不同主机上甚至是不同的数据中心中。

# 块存储和对象存储

{% asset_img  OS_VS_BS.png Block storage vs object storage %}

对象存储不像块存储，它不将文件切分为原始数据块。相反，数据被作为一个包括真实文件数据、元数据和唯一标识符的对象进行存储。注意元数据可以包括与对象有关的任何文本。

现代企业数据中心越来越像私有云，使用对象存储作为事实上的存储标准。对象存储可以以高可用、高容错的方式提供更好的扩展经济性，确保数据可以全球可用。

以下是块存储和对象存储的详细对比：

{% asset_img The_detailed_comparison.png The detailed comparison %}

# 为何对象存储如此重要

Hadoop一度成为数据湖选型的主宰。但是现在技术发展迅速，已经出现了更加先进的解决方案。现代数据湖基于对象存储，使用包括Apache Spark、Presto、TensorFlow等工具进行高级分析和机器学习。

让我们回顾过去，看看事情是如何改变的。Hadoop出现在21世纪前十年，并且在过去5年内非常流行。事实上，因为许多公司都得益于开源，5、6年前的许多大数据项目都基于Hadoop。

简单的说，Hadoop有两个主要的功能：

- 分布式文件系统（HDFS）用来存储数据
- 处理框架（MapReduce）可以并行地处理这些数据

越来越多的组织开始希望处理和分析他们拥有的全部数据，而不只是一部分。所以，Hadoop逐渐流行因为它可以存储和处理新的数据源，包括系统日志、点击流、传感器和机器生成的数据。

在2008-2009年左右，游戏改变了。当时，Hadoop的主要设计目标是利用通用商业硬件构建一个本地集群，从而以较低的成本存储和处理这些新数据。Hadoop非常适合这个目标。这在当时是正确的，但在今天却不是。

# Spark的出现

开源世界最美妙的是新事物不断涌现，最坏的事情也是如此。

我的意思是，随着最新的、最大的、最好的新项目陆续推出，你不得不追随潮流。让我们看看现在发生了什么。

近年来，比MapReduce更新的扩建不断涌现：Apache Spark。从概念是看，它与MapReduce相似。但是一个重要的不同是，它优化了Hadoop原本基于硬盘的计算方式，改为基于内存的数据计算。这导致了运行在Spark上的算法运行速度显著加快。

事实上，今天要开始建设一个大数据项目，如果没有强制要求与历史遗留的Hadoop或MapReduce应用协同的话，Spark是最佳的方案。你仍然需要持久化数据，因为Spark已经捆绑了许多Hadoop发行版，大多数本地集群使用HDFS。但是，随着云计算的兴起，出现了持久化数据更好的方式：对象存储。

对象存储不同于文件存储和块存储。因为它将数据存储为一个对象，而不是一个构成文件的数据块。元数据与该文件绑定，就不需要在文件存储中的使用的层级结构，并且没有限制元数据的大小。任何内容都可以存储在易于扩展的扁平的地址空间。

# 对象存储的诸多优势

根本上来讲，对象存储在大文件和高流量吞吐方面性能优越。它可以运行数据跨区域存储，容量可以无限扩展至P字节甚至更大，它提供可以帮助取回文件的自定义的元数据。

许多公司，特别是运营私有云环境的公司，将对象存储视作达到合规要求的一种面向非结构化大数据的长期存储库。但是合规性并不是唯一的原因。公司可以使用对象存储在Facebook上保存照片，在Spotify上保存歌曲，在Dropbox上保存文件。

事实上对象存储让人们更为青睐的原因是成本优势。使用对象存储的成本较使用HDFS的块存储成本低许多。你可以看看大部分的云计算提供商，对象存储的成本只是块存储的1/3到1/5。这意味着在HDFS存储相同容量的数据要比使用对象存储贵3-5倍。

综上所述，Spark是一个比MapReduce更快的框架，对象存储是比使用块存储的HDFS更便宜。下面我们把这两部分放在一起，形成一个新的架构。

# 对象存储+Spark的优势

我们特别推荐的是在云环境中基于对象存储和Spark构建数据湖。对象存储和Spark的解决方案比基于Hadoop的数据湖解决方案更具扩展性、成本更低。

在云环境中将对象存储与Spark结合，比经典的Hadoop/MapReduce配置更有弹性。如果你曾经在Hadoop集群中增加或移除节点，你肯定理解我的意思。即使配置也并不容易，但是在云环境下这个工作并不重要。

灵活性的另一个方面。如果要使用Hadoop增加更多的存储容量，你需要增加更多的（计算）节点。不论你是否需要计算能力，你都在需要存储能力的时候，无形中增加了计算容量。

对象存储架构则完全不同。如果需要更多的计算能力，只需要扩充Spark集群，而使存储集群保持不变。如果需要存储新的数据，只需要扩充对象存储即可。在云环境下，计算和存储不只是弹性的，并且是独立弹性的。这样非常不错，因为我们需要计算和存储具备独立的弹性。

# 对象存储+Spark

## 业务敏捷

要获得性能提升有许多方式。

## 稳定性、可靠性



## 更低的TCO



